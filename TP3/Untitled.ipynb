{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "continuing-lewis",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "subjective-acting",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "selected-frank",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "exact-geology",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/train.csv\", sep = ';').to_numpy()\n",
    "x_test = pd.read_csv(\"data/test_public.csv\", sep = ';').to_numpy()\n",
    "\n",
    "#Deleting the first column (id) since it's not relevant for the prediction\n",
    "data = np.delete(data, 0, 1)\n",
    "x_test = np.delete(x_test, 0, 1)\n",
    "\n",
    "for i in range(len(data)):\n",
    "    if data[i][0]=='white':\n",
    "        data[i][0]=0\n",
    "    elif data[i][0]=='red':\n",
    "        data[i][0]=1\n",
    "        \n",
    "for i in range(len(x_test)):\n",
    "    if x_test[i][0]=='white':\n",
    "        x_test[i][0]=0\n",
    "    elif x_test[i][0]=='red':\n",
    "        x_test[i][0]=1\n",
    "        \n",
    "train = data[:3600]\n",
    "valid = data[3600:]\n",
    "\n",
    "x_train = train.T[:12].T\n",
    "y_train = train[:,12]\n",
    "\n",
    "x_valid = valid.T[:12].T\n",
    "y_valid = valid[:,12]\n",
    "\n",
    "y = []\n",
    "for i in y_train:\n",
    "    y.append(int(i))\n",
    "y_train = y\n",
    "\n",
    "y = []\n",
    "for i in y_valid:\n",
    "    y.append(int(i))\n",
    "y_valid = y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "junior-agency",
   "metadata": {},
   "source": [
    "# Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "convertible-footage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = DecisionTreeClassifier()\n",
    "\n",
    "selector = RFE(classifier, n_features_to_select=10, step=1)\n",
    "selector = selector.fit(x_train, y_train)\n",
    "selector.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dental-leisure",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deleting white/red wine column\n",
    "x_train = np.delete(x_train, 0, 1)\n",
    "x_valid = np.delete(x_valid, 0, 1)\n",
    "x_test = np.delete(x_test, 0, 1)\n",
    "\n",
    "#Deleting fixed acidity column\n",
    "x_train = np.delete(x_train, 0, 1)\n",
    "x_valid = np.delete(x_valid, 0, 1)\n",
    "x_test = np.delete(x_test, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "weighted-decrease",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = DecisionTreeClassifier()\n",
    "\n",
    "selector = RFE(classifier, n_features_to_select=10, step=1)\n",
    "selector = selector.fit(x_train, y_train)\n",
    "selector.ranking_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "changing-tracy",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "under-underground",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45195353748680045"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = BernoulliNB()\n",
    "classifier = classifier.fit(x_train, y_train)\n",
    "predictions_valid = classifier.predict(x_valid)\n",
    "accuracy_score(y_valid, predictions_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "narrative-hollow",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\louis\\.julia\\conda\\3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4857444561774023"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = LogisticRegression()\n",
    "classifier = classifier.fit(x_train, y_train)\n",
    "predictions_valid = classifier.predict(x_valid)\n",
    "accuracy_score(y_valid, predictions_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "desirable-korea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\louis\\.julia\\conda\\3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.470960929250264"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = LinearSVC()\n",
    "classifier = classifier.fit(x_train, y_train)\n",
    "predictions_valid = classifier.predict(x_valid)\n",
    "accuracy_score(y_valid, predictions_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "handled-organic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4804646251319958"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = KNeighborsClassifier()\n",
    "classifier = classifier.fit(x_train, y_train)\n",
    "predictions_valid = classifier.predict(x_valid)\n",
    "accuracy_score(y_valid, predictions_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "failing-northern",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5913410770855333"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = DecisionTreeClassifier()\n",
    "classifier = classifier.fit(x_train, y_train)\n",
    "predictions_valid = classifier.predict(x_valid)\n",
    "accuracy_score(y_valid, predictions_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "pursuant-market",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6779303062302007"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = RandomForestClassifier()\n",
    "classifier = classifier.fit(x_train, y_train)\n",
    "predictions_valid = classifier.predict(x_valid)\n",
    "accuracy_score(y_valid, predictions_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "mental-peripheral",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\louis\\.julia\\conda\\3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 3, 'max_leaf_nodes': 10, 'min_samples_split': 2}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5586061246040127"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = [{'max_depth': np.arange(1,10,1),\n",
    "           'max_leaf_nodes': [5,10,15], \n",
    "           'min_samples_split': [2,5,10]}]\n",
    "\n",
    "classifier = GridSearchCV(DecisionTreeClassifier(), params, refit=True)\n",
    "classifier = classifier.fit(x_train, y_train)\n",
    "\n",
    "print(classifier.best_params_)\n",
    "\n",
    "predictions_valid = classifier.predict(x_valid)\n",
    "accuracy_score(y_valid, predictions_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "compact-unemployment",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\louis\\.julia\\conda\\3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 17, 'n_estimators': 1000}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6789862724392819"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = [{'max_depth': [17,18],\n",
    "           'n_estimators': [400,1000]}]\n",
    "\n",
    "classifier = GridSearchCV(RandomForestClassifier(criterion='entropy'), params, refit=True)\n",
    "classifier = classifier.fit(x_train, y_train)\n",
    "\n",
    "print(classifier.best_params_)\n",
    "\n",
    "predictions_valid = classifier.predict(x_valid)\n",
    "accuracy_score(y_valid, predictions_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tutorial-watch",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "prescription-profile",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = classifier.predict(x_test)\n",
    "\n",
    "\n",
    "with open('submission.csv', 'w', newline = '') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['id', 'quality'])\n",
    "    for i in range(len(predictions)):\n",
    "        writer.writerow([i,predictions[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "balanced-rebound",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
